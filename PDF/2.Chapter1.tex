
%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************
%!TEX root = 0.main.tex

\section{Graph Spherical Convolutions}
[Stating the problem we want to solve]\\
Defferrard et al. \cite{DeepSphere} use in their Graph CNN the Heat Kernel Graph Laplacian proposed by Belkin et al. \cite{Belkin:2005:TTF:2138147.2138189} on the HEALPix sampling of the sphere in order to obtain a graph whose convolution approximates the convolution on the sphere but limit the number of neighbors of each node of the graph in order to limit the computational complexity of the algorithm to be linear with the dimension of the input data. Despite Belkin et al. proved a result of spectral convergence of their graph Laplacian to the Laplace-Beltrami operator for any manifold given a random sampling \ref{theo:Belkin spectral convergence}, in the work of Defferrard et al. the graph Laplacian does not seem to show the expected spectral convergence to the continuous Laplace-Beltrami operator (see figure \ref{fig:Old spectrum}) 

[Stating what we did to solve it]\\
In this chapter we give three contributions: first, in section \ref{sec:pointwise convergence of the Heat Kernel Graph Laplacian on the Sphere} we prove a pointwise convergence result of the full graph Laplacian in the case of the sphere on a deterministic sampling that is regular enough; second, in section \ref{sec:How to build a good graph} we show a way of modifying the graph of Defferrard et al. to recover the expected spectral convergence and still managing to contain the computational costs of graph convolutions; finally in section \ref{sec:Experimental validation} we study how the graph proposed in section \ref{sec:How to build a good graph} performs in practice when used in a Graph Convolutional Neural Network, comparing its performances to DeepSphere \cite{DeepSphere}.

\subsection{Definitions and basic results}
[ I'll move this section to the previous Chapter when introducing the work of Belkin et al. For now I'll leave it here for completeness]\\
Let us recall some basic definitions necessary for this chapter:
\vspace{0.5cm}
\begin{definition}{}(Heat Kernel Graph Laplacian Matrix)\\
	\label{def:Heat Kernel Graph Laplacian Matrix}
	Given a sampling $ \mathcal P = \{x_i\in\mathcal M\}_{i=0}^{n-1}$ on a $k$-dimensional manifold $\mathcal M\subset \mathbb R^N$ we construct the full graph defined by the adjacency matrix 
	$$(\mathbf W)_{ij}=e^{-\frac{||x_i-x_j||^2}{4t}}$$
	 where $||\cdot||$ is the Euclidean norm in the ambient space $\mathbb R^N$ and we define the corresponding Heat Kernel Graph Laplacian by the \textbf{matrix} 
    $$(\mathbf{L}_n^t)_{ij}=\begin{cases}
    \sum_k W_{ik} & \text{if }i=j\\
    -W_{ij}&\text{if }i\neq j
    \end{cases}$$
\end{definition}
\vspace{0.5cm}
Observe that given a function $f: \mathcal P \rightarrow \mathbb R$ defined on the sampling $ \mathcal P$ and defined the vector $\mathbf f\in\mathbb R^n$ such that $\mathbf f_i = f(x_i)$, the Heat Kernel Graph Laplacian matrix acts on $\mathbf f$ in the following way:
$$ (\mathbf L_n^t \mathbf f)_i:=  \sum_{j=0}^{n-1} e^{-\frac{||x_i-x_j||^2}{4t}}\left(f(x_i)-f(x_j)\right)$$

\vspace{0.5cm}
\begin{definition}{}(Heat Kernel Graph Laplacian operator)\\
	\label{def:Heat Kernel Graph Laplacian operator}
	\text{Given a sampling $\{x_i\in\mathcal M\}_{i=0}^{n-1}$ of the manifold we define the \textbf{operator} }$L_n^t$ such that
	$$L_n^tf(y) := \frac{1}{n}\left[ \sum_{i=0}^{n-1} e^{-\frac{||x_i-y||^2}{4t}}\left(f(y)-f(x_i)\right)\right]$$
\end{definition}
\vspace{0.5cm}
Observe that the Heat Kernel Graph Laplacian operator restricted on the sample points $x_0, ..., x_{n-1}$ acts as the Heat Kernel Graph Laplacian matrix rescaled by a factor of $\frac{1}{n}$:
$$L_n^tf(x_i) = \frac{1}{n}\mathbf (L_n^t\mathbf f)_i$$
\vspace{0.5cm}
\begin{definition}{}(Functional approximation to the Laplace-Beltrami operator)\\ \label{eq: my L^t} Let $\mu$ be the uniform probability measure on the manifold $\mathcal M$, that is the probability measure given by the induced metric on $\mathcal M$ rescaled by a factor $\frac{1}{|\mathcal M|}$, where $|\mathcal M|$ is the volume of $\mathcal M$. We define the functional approximation to the Laplace-Beltrami operator to be the operator $L^t$ such that
	\label{def:Functional approximation to the Laplace-Beltrami operator}
	$$ L^tf(y) = \int_{\mathcal M}e^{-\frac{||y-x||^2}{4t}}\left(f(y)-f(x)\right)d\mu(x)$$
\end{definition}
\vspace{0.5cm}
We conclude by stating a result that we will need in the next section:
\vspace{0.5cm}
\begin{prop}(Hoeffding's inequality)\\
	Let \(X_{1}, \ldots, X_{n}\) be independent identically distributed random variables, such that
	\(\left|X_{i}\right| \leqslant K .\) Then
	
	$$
	\mathbb P\left\{\left|\frac{\sum_{i} X_{i}}{n}-\mathbb{E} X_{i}\right|>\epsilon\right\}<2 \exp \left(-\frac{\epsilon^{2} n}{2 K^{2}}\right)
	$$
	\label{theo:Hoeffding}
\end{prop}
\subsection{Pointwise convergence of the Heat Kernel Graph Laplacian on the Sphere}
\label{sec:pointwise convergence of the Heat Kernel Graph Laplacian on the Sphere}
[Review of Belkin et al's proof]\\ 
As saw in Section \ref{sec:Chapter0: belkins trinity} Belkin et al. prove different convergence results for the random Heat Kernel Graph Laplacian; in this Section we are interested in the following pointwise convergence result for the Heat Kernel Graph Laplacian operator (proven in \cite{Belkin:2005:TTF:2138147.2138189}):
\vspace{0.5cm}
\begin{theorem}{from \cite[Belkin et al.]{Belkin:2005:TTF:2138147.2138189}}\\
	\label{theo:Belkin pointwise convergence}
	Let $\mathcal M$ be a $k$-dimensional compact smooth manifold embedded in some euclidean space $\mathbb R^N$. Let the data points $x_1, ... x_n$ be sampled form a uniform distribution on the manifold $\mathcal M$. Set $t_n=n^{-\frac{1}{k+2+\alpha}}$, for any $\alpha>0$ and let $f\in\mathcal C_\infty(\mathcal M)$. Then:
	
	$$\forall \epsilon>0\quad \mathbb{P}\left[\left|\frac{1}{t}\frac{1}{(4 \pi t)^{k/2}}L_{n}^{t_n} f(p)-  \frac{1}{|\mathcal M|}L^{t_n} f(p)\right|>\epsilon\right] \xrightarrow{n\to\infty} 0$$
\end{theorem}
\vspace{0.5cm}

This theorem states a rather weak convergence of $L_n^t$ to $L^t$, that is far from being as strong as spectral convergence, proven in theorem \ref{theo:Belkin spectral convergence}. However, we want to show that a similar result still holds in the specific case of the manifold $\mathcal M$ being the 2-Sphere $\mathbb S_2$ and where the points $x_1, ..., x_n$ are not sampled form a random distribution on $\mathbb S_2$, but are defined by the HEALPix sampling. To understand the differences between theorem \ref{theo:Belkin pointwise convergence} and theorem \ref{theo:pointwise convergence in the healpix case} it is useful to first review the proof of theorem \ref{theo:Belkin pointwise convergence}.
\begin{proof}[Proof of Theorem \ref{theo:Belkin pointwise convergence}]
The first step is to observe that for any fixed $t>0$, any fixed function $f$ and a fixed point $y\in\mathbb S_2$,  the Heat Kernel Graph Laplacian $L_n^t$ is an unbiased estimator for the Functional Approximation of the Laplace-Beltrami $L^t$. In other words, $L_n^tf(y)$ is the empirical average of $n$ i.i.d. random variables $X_i= e^{-\frac{||x_i-y||^2}{4t}}\left(f(y)-f(x_i)\right)$ with expected value corresponding to $L^tf(y)$. Thus,
\begin{equation}
\label{eq:expected value of heat kernel grah laplacian}
	\mathbb E L_n^tf(y) = 	\mathbb E \frac{1}{n}X_i = \mathbb E X_i = L^tf(y)
\end{equation}
and for the strong law of large numbers we have that
\begin{equation}
\label{eq:convergence in probability}
\lim_{n\to\infty}L_n^tf(y) = L^t(y)
\end{equation}
where the limit is in the sense of the strong law of large numbers.
The core of the work of Belkin et al. is the proof, that we will not discuss, of the following proposition:

\begin{prop} Under the same hypothesis of theorem \ref{theo:Belkin pointwise convergence},
	$$\frac{1}{t}\frac{1}{(4\pi t)^{k/2}} L^tf(y) \xrightarrow{t\to 0 } \frac{1}{|\mathcal M|}\triangle_{\mathcal M}f(y)$$
	\label{prop:3}
\end{prop}

Thanks to Proposition \ref{prop:3} and equation \ref{eq:convergence in probability}, a straightforward application of Hoeffding's inequality with $K=\frac{1}{t}\frac{1}{(4\pi t)^{k/2}}$ together with equation  \ref{eq:expected value of heat kernel grah laplacian} leads to

\begin{equation}
	\label{eq:hoeffding applied}
	\mathbb{P}\left[\frac{1}{t(4 \pi t)^{k / 2}}\left|L_{n}^{t} f(y)- L^{t} f(y)\right|>\epsilon\right] \leq 2 e^{-1 / 2 \epsilon^{2} n t(4 \pi t)^{k / 2}}
\end{equation}

We want the right hand side of equation \ref{eq:hoeffding applied} to go to $0$ for $n\to\infty, t\to0$ at the same time. For this to happen, we need to find a sequence $(t_n)$ such that 
$$\begin{cases}
t_n\xrightarrow{n\to\infty}0\\
2 e^{-1 / 2 \epsilon^{2} n t_n(4 \pi t_n)^{k / 2}}\xrightarrow{n\to\infty}0\\
\end{cases}$$

By fixing $t_n=n^{-\frac{1}{k+2+\alpha}}$, for any $\alpha>0$, it is easy to check that $-1 / 2 \epsilon^{2} n t_n(4 \pi t_n)^{k / 2}\xrightarrow{n\to\infty}+\infty$ concluding the proof.

\end{proof}

Now we can observe that in order to adapt this proof to the case of the sphere with the HEALPix sampling  we need to modify two key things. First, due to the deterministic nature of the HEALPix sampling on the sphere, we need to prove that for any fixed $t>0$, any fixed function $f$ and any point $y\in\mathbb S_2$ 
$$\left|L_n^tf(y)-L^tf(y)\right|\xrightarrow{n\to \infty} 0$$
without relying on the strong law of large numbers. Once proven such result, we need to prove that

$$\left|\frac{1}{4\pi t^2}\left(L_n^tf(x) - L^tf(x)\right)\right|\xrightarrow[n\to \infty]{t\to 0}0$$

Once proven the limit above, Proposition \ref{prop:3} leads to our main result:
\vspace{1cm}
\begin{theorem}
	For a sampling $\mathcal P = \{x_i\in\mathbb S_2\}_{i=0}^{n-1}$ of the sphere, for all $f: \mathbb S_2 \rightarrow \mathbb R$ Lipschitz with respect to the euclidean distance, for all $y\in\mathbb S_2$, the rescaled Heat Kernel Graph Laplacian operator $\frac{|\mathbb S_2|}{4\pi t_n}L^t_n$ converges pointwise to the Laplace Beltrami operator on the sphere $\triangle_{\mathcal M}$
	
	$$ \lim_{N\to\infty}\frac{|\mathbb S_2|}{4\pi t_N^2} L_n^{t_N}f(y) =  \triangle_{\mathbb S_2}f(y) $$
	\label{theo:pointwise convergence in the healpix case}
\end{theorem}
\vspace{1cm}

We need now to define some geometrical quantities that we'll need in the proof.
Given a HEALPix sampling $x_0, ..., x_{n-1}$, define $N$ to be a shorthand for the HEALPix parameter $N_{side}$ (remember that for HEALPix sampling, $n=12N^2$). Define $\sigma_i$ to be the patch of the surface of the sphere corresponding to the i-th point of the sampling, define $A_i$ to be its corresponding area and $d_i$ to be the radius of the smallest ball in $\mathbb R^3$ containing the i-th patch (see Figure \ref{fig:Geometric characteristics of a patch}). Define $d^{(n)} := \max_{i=0, ..., n}d_i$ and $A^{(n)}=\max_{i=0, ..., n}A_i$.\\

\begin{minipage}{.5\textwidth}
	\centering
	\includegraphics[width=0.4\linewidth]{figs/chapter1/d_iA_i.jpg}
	\captionof{figure}{Geometric characteristics of the i-th patch}
	\label{fig:Geometric characteristics of a patch}
\end{minipage}%
\begin{minipage}{.5\textwidth}
	\centering
	\includegraphics[width=0.7\linewidth]{figs/chapter1/Heal_Base.png}
	\captionof{figure}{HEALPix equal areas patches for $N_{side}=1$, $N_{side}=2$}
	\label{fig:HEALPix equal areas patches}
	\vspace{0.5cm}
\end{minipage}

\subsubsection{Proof of the pointwise convergence of the Heat Kernel Graph Laplacian on the Sphere}

Our first goal is to prove the following Proposition: 
\vspace{0.5cm}
\begin{prop}\label{prop:1}
	For a sampling $\{x_i\in\mathbb S_2\}_{i=0}^{n-1}$ of the sphere, for all $f: \mathbb S_2 \rightarrow \mathbb R$ Lipschitz with respect to the euclidean distance $||\cdot||$, for all $y\in\mathbb S_2$, the Heat Kernel Graph Laplacian operator $L^t_n$ converges pointwise to the functional approximation of the Laplace Beltrami operator $L^t$
	$$ L_n^tf(y)\xrightarrow{n\to\infty} L^tf(y)$$
\end{prop} 
\vspace{0.5cm}


\begin{proof}
	We know by construction that the HEALPix sampling cut the sphere into equal areas i.e $\forall i=0, ..., n-1\quad A_i = A^{(n)}) $.
	Let us assume that the function $f:\mathbb R^3\rightarrow \mathbb R$ is Lipschitz with Lipschitz constant $\mathcal L_f$, we have 
	
	$$\left| \int_{\sigma_{i}}f({\bf x})\text{d}{\mu(x)} - \frac{1}{n}f(\mathbf x_i)\right| \leq \mathcal L_fd^{(n)}\frac{1}{n} $$

	So, by triangular inequality and by summing all the contributions of all the $n$ patches
	$$\left| \int_{\mathbb S_2}f({\bf x})\text{d}{\mu(x)} - \frac{1}{n}\sum_i f(\mathbf x_i)\right| \leq \sum_i \left| \int_{\sigma_{i}}f({\bf x})\text{d}{\mu(x)} - \frac{1}{n}f(\mathbf x_i)\right|\leq n  \mathcal L_fd^{(n)}\frac{1}{n} = \mathcal L_fd^{(n)}$$	
	Thanks to this result, we have the following two pointwise convergences
	
	$$\forall f \text{ Lipschiz,}\quad \forall y\in\mathbb S_2,  \quad\quad \frac{1}{n}\sum_i e^{-\frac{||x_i-y||^2}{4t}}\rightarrow \int e^{-\frac{||x-y||^2}{4t}}d\mu(x)$$
	$$\forall f \text{ Lipschiz,}\quad \forall y\in\mathbb S_2,  \quad\quad \frac{1}{n}\sum_i e^{-\frac{||x_i-y||^2}{4t}}f(x_i)\rightarrow \int e^{-\frac{||x-y||^2}{4t}}f(x)d\mu(x)$$
	
	Definitions \ref{def:Heat Kernel Graph Laplacian operator} and \ref{def:Functional approximation to the Laplace-Beltrami operator} end the proof.
\end{proof}
\vspace{0.5cm}

Now, we just proved that \textit{keeping t fixed} $L_n^tf(x)\rightarrow L^tf(x)$. Now our goal is to prove that:

\vspace{0.5cm}
\begin{prop}\label{prop:2}
	Given a sampling regular enough i.e. for which we assume $d^{(n)}\leq \frac{C}{\sqrt{n}}$, for a fixed $t>0$, a fixed Lipschitz function $f$ and a fixed point $y\in\mathbb S_2$
$$\left|\frac{1}{4\pi t^2}\left(L_n^tf(x) -L^tf(x)\right)\right|\rightarrow0$$
\textit{for $t\to0$ and $n\to\infty$ at the same time}. In other words, there exists a sequence $(t_n), \\ \lim_{n\to\infty}t_n=0$ such that 
$$\forall f \text{ Lipschitz, } \forall x\in\mathbb S_2 \quad \left|\frac{1}{4\pi t_n^2}\left(L_n^{t_n}f(x) - L^{t_n}f(x)\right)\right|\xrightarrow{n\to \infty}0$$
\end{prop}
\vspace{0.5cm}

The main result of this section, theorem  \ref{theo:pointwise convergence in the healpix case}, is then an immediate consequence of Proposition \ref{prop:2} and Proposition \ref{prop:3}.


\begin{proof}[Proof of Proposition \ref{prop:2}]
	
	We define for simplicity of notation
	$$\phi^t(x;y) := e^{-\frac{||x-y||^2}{4t}}\left(f(y)-f(x)\right)$$
	$$K^t(x,y) :=  e^{-\frac{||x-y||^2}{4t}}$$

	
	we start by writing the following chain of inequalities
	$$||L_n^tf-L^tf||_\infty = \max _{y\in \mathbb S_2} \left|L_n^tf(y)-L^tf(y)\right|=$$
	$$= \max _{y\in \mathbb S_2} \left| \frac{1}{n} \sum_{i=1}^n \phi^t(x_i; y)- \int_{\mathbb S_2} \phi^t(x;y)d\mu(x) \right|$$
	$$\leq \max _{y\in \mathbb S_2}  \sum_{i=1}^n   \left| \frac{1}{n}  \phi^t(x_i; y)- \int_{\sigma_i} \phi^t(x;y)d\mu(x) \right|$$

	$$\leq  \max _{y\in \mathbb S_2} \left[\mathcal L_{\phi^t_y}d^{(n)} \right]$$
	
	where $\mathcal L_{\phi^t_y}$ is the Lipschitz constant of $x \rightarrow \phi^t(x, y)$ and where we used for the last inequality the arguments used in the proof of Proposition \ref{prop:1}. If we assume $d^{(n)}\leq \frac{C}{\sqrt{n}}$ and remember that for HEALPix $n=12N^2$ we have that
	
	$$||L_n^tf-L^tf||_\infty  \leq  \max _{y\in \mathbb S_2} \left[ \mathcal L_{\phi^t_y} \frac{C}{N} \right]$$
	
	Let's now find the explicit dependence $t\rightarrow \mathcal L_{\phi^t_y}$
	
	$\mathcal L_{\phi^t_y} = ||\partial_x\phi^t(x;y)||_\infty = ||\partial_x\left(K^t(x;y)f(x)\right)||_\infty = ||\partial_x K^t(x;y)f(x) + K^t(x;y)\partial_x f(x)||_\infty \leq$
	
	$ \leq ||\partial_x K^t(x;y)f(x)||_\infty + ||K^t(x;y)\partial_x f(x)||_\infty \leq  ||\partial_x K^t(x;y)||_\infty||f(x)||_\infty + ||K^t(x;y)||_\infty||\partial_x f(x)||_\infty = $
	
	$ = ||\partial_x K^t(x;y)||_\infty||f(x)||_\infty + ||\partial_x f(x)||_\infty = \mathcal L_{K^t_y} ||f||_\infty + ||\partial_xf||_\infty = \mathcal L_{K^t_y} ||f||_\infty + \mathcal L_f$
	
	where $\mathcal L_{K^t_y}$ is the Lipschitz constant of $x\rightarrow K^t(x;y)$. We can observe that such constant does not depend on $y$:
	
	$\mathcal L_{K^t_y} = \norm{\partial_x e^{-\frac{x^2}{4t}}}_\infty = \norm{\frac{x}{2t}e^{-\frac{x^2}{4t}}}_\infty = \left. \frac{x}{2t}e^{-\frac{x^2}{4t}}\right|_{x=\sqrt{2t}}=(2et)^{-\frac{1}{2}}\propto t ^ {-\frac{1}{2}}$
	
	So we can continue
	
	$$ \max _{y\in \mathbb S_2} \left[  \mathcal L_{\phi^t_y} \frac{C}{N} \right]\leq$$
	$$ \leq  \frac{C}{N} \left( (2et)^{-\frac{1}{2}} \norm{f}_\infty + \mathcal L_f \right)\leq$$
	$$  \leq \frac{C\norm{f}_\infty}{N(2et)^\frac{1}{2}} +   \frac{C}{N}\mathcal L_f$$
	
	So we have that, rescaling by a factor $\frac{1}{4\pi t^2}$
	
	$$\norm{\frac{1}{4\pi t^2}\left(L_n^tf-L^tf\right)}_\infty\leq$$
	$$\leq \frac{1}{4\pi t^2}\norm{\left(L_n^tf-L^tf\right)}_\infty \leq$$
	$$ \leq \frac{C}{4\pi}\left[\frac{\norm{f}_\infty}{\sqrt{2e}}\frac{1}{Nt^\frac{5}{2}} + \frac{\mathcal L_f}{Nt^2}\right]$$
	
	we want $\begin{cases}
	t \rightarrow 0\\
	N \rightarrow \infty\\
	Nt^\frac{5}{2} \rightarrow \infty\\
	Nt^2 \rightarrow \infty
	\end{cases}$ in order for $ \frac{C}{4\pi}\left[\frac{\norm{f}_\infty}{\sqrt{2e}}\frac{1}{Nt^\frac{5}{2}} + \frac{\mathcal L_f}{Nt^2}\right] \xrightarrow[t\to 0 ]{N\to\infty}0$
	
	This is true if $\begin{cases}
	t(N) = N^\beta, &\beta\in(-\frac{2}{5}, 0) \\
	t(N) = N^\beta, &\beta\in(-\frac{1}{2}, 0)
	\end{cases} \implies t(N) = N^\beta, \quad \beta\in(-\frac{2}{5}, 0)$
	
	Indeed 
	
	$Nt^\frac{5}{2}=N^{\frac{5}{2}\beta+1}\xrightarrow{N \to \infty} \infty$ since $\frac{5}{2}\beta+1>0 \iff \beta>-\frac{2}{5}$
	
	$Nt^2=N^{2\beta+1}\xrightarrow {N \to \infty} \infty$ since $2\beta+1>0 \iff \beta>-\frac{1}{2}$
	
	So, for $t=N^\beta$ with $\beta\in(-\frac{2}{5}, 0)$ we have that 
	
	$$\begin{cases}
	(t_N)\xrightarrow{N\to\infty}0\\
	\norm{\frac{1}{4\pi t_N^2}L_n^{t_N}f-\frac{1}{4\pi t_N^2}L^{t_N}f}_\infty  \xrightarrow{N\to\infty}0
	\end{cases}$$
	
\end{proof}

The proof of theorem \ref{theo:pointwise convergence in the healpix case} is now trivial:
\begin{proof}[Proof of Theorem \ref{theo:pointwise convergence in the healpix case}]
	Thanks to Proposition \ref{prop:2} and Proposition \ref{prop:3}	we conclude that $\forall y\in\mathbb S_2 $
	$$\lim_{N\to\infty}\frac{1}{4\pi t_N^2} L_n^{t_N}f(y) =  \lim_{N\to\infty}\frac{1}{4\pi t_N^2} L^{t_N}f(y) = \frac{1}{|\mathbb S_2|}\triangle_{\mathbb S_2}f(y) $$
\end{proof}


[Why proving this result is useful] The proof of this result is instructive since it shows that we need to impose some regularity conditions on the sampling. If the sampling is equal area as HEALPix, meaning that all the patches $\sigma_i$ have the same area (i.e. HEALPix, see figure \ref{fig:HEALPix equal areas patches}), then we need to impose that $ d^{(n)}\leq \frac{1}{\sqrt{n}}$. If the sampling is not equal area, meaning that in general $A_i\neq A_j$, it can be shown that we need a slightly more complex condition: $\max_{i=0,...,n-1}d_iA_i\leq Cn^{-\frac{3}{2}}$.\\
In \cite{Belkin:2005:TTF:2138147.2138189} the sampling is drawn form a uniform random distribution on the sphere, and their proof heavily relies on the uniformity properties of the distribution from which the sampling is drawn. In our case the sampling is deterministic, and the fact that for a sphere there doesn't exist a regular sampling with more than 12 points (being the only regular samplings of the sphere the vertices of the Platonic solids) is indeed a problem that we need to overcome someway by having to impose the regularity conditions above. 


To conclude, we can see that the result obtained has the same form than the result obtained in \cite{Belkin:2005:TTF:2138147.2138189}. If Belkin et al. proved convergence in the random case for $\beta \in (-\frac{1}{4}, 0)$, we proved convergence in the HEALPix case for $\beta \in (-\frac{2}{5}, 0)$. This kind of result can be interpreted in the following way. In order to have this pointwise convergence, we need to reduce the kernel width but \textit{not so fast} compared to the resolution of the graph. In other words, the kernel width has to be reduced but is somewhat limited by the resolution of the graph. In the next section we
\begin{remark}
	Pointwise convergence is just a necessary condition for spectral convergence.  Theorem \ref{theo:pointwise convergence in the healpix case} do not imply convergence of eigenvalues and eigenvectors.
\end{remark}

\clearpage
\subsection{How to build a good graph to approximate spherical convolutions}
\label{sec:How to build a good graph}
The current state of the art of rotation equivariant Graph CNN is DeepSphere \cite{DeepSphere}. However, if we measure the alignment of the eigenspaces spanned by the eigenvectors of the graph Laplacian used in \cite{DeepSphere} and the ones spanned by the spherical harmonics we see that it does not get better as $N_{side}$ increases (figure \ref{fig:deepsphere results}). We'll see that the main cause of this bad behavior of the eigenspaces is the fixed number of neighbors used in \cite{DeepSphere} for the construction of the graph. In this subsection we'll see that to obtain the desired spectral convergence it is necessary to increase the number of neighbors as we decrease the kernel width $t$. We'll follow in practice what we did in proving theorem \ref{theo:pointwise convergence in the healpix case}: first we'll build a \textit{full graph}, and let the number of pixels $n$ increase while keeping the kernel width $t$ fixed. After having discussed the results, we'll try to find a possible sequence $(t_n)$ in order to obtain the expected spectral convergence. Only in the end we'll find a way to make the graph sparse to limit the computational costs of graph convolutions but keeping the eigen decomposition of the graph Laplacian as close to the spherical harmonics as possible.
\begin{figure}[h!]
	\label{fig:deepsphere results}
	
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/deepsphere_original.png}
		\includegraphics[width=0.7\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/deepsphere_original_diagonal.png}	
		\caption{Correspondence between the subspaces spanned by the graph Fourier modes and the spherical harmonics of the graph Laplacian of DeepSphere. First, we compute the power spectral density (PSD) of each graph eigenvector with a discrete Spherical Harmonic Transform. Second, as there is $2\ell + 1$ spherical harmonics for each degree $\ell$, we sum the contributions of the corresponding $2\ell + 1$ graph eigenvectors. Thus, the entry $(i, j)$ of the matrix correspond to the percentage of energy of the j-th eigenspace of the graph Laplacian contained in the i-th eigenspace spanned by the true spherical harmonics. In a perfect situation, this matrix would be the identity matrix.
			It can be seen that the Fourier eigenvectors of the graph Laplacian span almost the same subspaces as the spherical harmonics in the low frequencies, but leak towards adjacent frequency bands at higher frequencies. 	For a clearer visualization and confront, we plot here the diagonal of the matrices.}
\end{figure}

\subsubsection{Full graph, $n\to\infty$}\label{sec:Chapter1: n to infty}
Here we analyze what happens to the power density spectrum of the \textit{full} Heat Kernel Graph Laplacian as we make $n$ go to infinity while keeping $t$ fixed. Since in the previous section we proved that (Proposition \ref{prop:3}) for a sampling regular enough and a fixed $t$, a fixed function $f$, a fixed point $y$
$$L_n^tf(y)\xrightarrow{n\to\infty}L^tf(y)$$
We expect to observe (even if we didn't prove it) the corresponding spectral convergence. The results obtained are in figure \ref{fig:n to infinity1}, \ref{fig:n to infinity3}.

\begin{figure}[h!]
	\label{fig:n to infinity1}
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/n.png}
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/n_diagonal.png}	
	\caption{Alignment of the eigenvectors of the Heat Kernel Graph Laplacian with a fixed kernel width $t$}
	
\end{figure}
\begin{figure}[h!]
	\label{fig:n to infinity3}
	\centering
	\includegraphics[width=0.7\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/n_eigenvalues.png}	
	\caption{Spectrum of the Heat Kernel Graph Laplacian with a fixed kernel width $t$}
\end{figure}

In figure \ref{fig:n to infinity1} and in figure \ref{fig:n to infinity2} we see two things: first that there's a frequency threshold beyond which the Graph Laplacian is completely blind, approximately located at the 15th degree, and second that before this frequency threshold, we actually see the convergence expected: the alignment gets better as $n$ gets bigger.

\begin{figure}[h!]
	\label{fig:n to infinity4}
	\centering
	\includegraphics[width=0.45\textwidth]{figs/chapter1/frequency_threshold1.png}	\hfill
	\includegraphics[width=0.45\textwidth]{figs/chapter1/frequency_threshold2.png}	
	\caption{Frequency threshold explained.}
\end{figure}

 To explain this we refer to figure \ref{fig:n to infinity4} where we show a simplified situation where we are sampling the interval $[0, 2]$ and we plot the Gaussian kernel centered around the first pixel of the sampling corresponding to the origin. On the leftmost image the pixels are correctly spaced with respect to the kernel width, in the sense that the values of the kernel evaluated on the pixels are well far apart from each other. This makes the graph able to "see" all the pixels differently, and thus all the frequencies with wavelength around the order of magnitude of the aerage pixel distance will be captured by the graph. On the rightmost image in figure \ref{fig:n to infinity4} there are too many pixels with respect to the kernel width: the values of the kernel evaluated on the pixels close to the origin, because of the slope of the kernel being almost zero are too close to each other (in red); because of this any variation of a signal on the red pixels would be almost invisible to the graph. with this kernel width $t$, no matter how much we sample the interval $[0,2]$, any frequency with wavelength shorter than the radius $r\approx0.25$ becomes "invisible" to the graph Laplacian.\\
 This phenomenon can be seen also in the spectrum represented in figure \ref{fig:n to infinity3} where we plot the eigenvalues of the matrix $\mathbf L_n^t$: as $N_{side}$ gets bigger the eigenvalues get more and more grouped in the usual groups of the same multiplicity of the corresponding spherical harmonics; however, there's a frequency (corresponding approximately to the degree $\ell=15$) from which all the eigenspaces tend to merge into one, corresponding to the eigenvalue $1$.
 
\subsubsection{Full graph, $t\to 0$}
In this section we fix the parameter $N_{side}$ and and we make the kernel width $t$ go to $0$. 
\begin{figure}[h]
	\label{fig:t_sensitivity_eigenspaces}
	\caption{Alignment of the eigenspaces of the Heat Kernel Graph Laplacian with a fixed number of points $n$}
	\centering
	\includegraphics[width=1\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/t_sensitivity.png}
	
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/t_sensitivity_diagonal.png}
	\caption{Whole trend}
	\label{fig:t_sensitivity_diagonal}
\end{figure}%
\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/t_sensitivity_diagonal_2.png}
	\caption{First trend: error stays low for low frequencies, and gets lower for high frequencies}
	\label{fig:t_sensitivity_diagonal_2}
	\vspace{0.5cm}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/t_sensitivity_diagonal_1.png}
	\caption{Second trend: error gets higher for both high and low frequencies}
	\label{fig:t_sensitivity_diagonal_1}
\end{figure}%

Results are in figure \ref{fig:t_sensitivity_eigenspaces}, \ref{fig:t_sensitivity_diagonal}: Starting from $t=0.32$, the error in the high frequencies starts to get smaller, while the error in the low frequencies keeps staying low (Figure \ref{fig:t_sensitivity_diagonal_2}) up to $t=0.05$. For $t$ that gets smaller and smaller up to $t=0.01$, we get worse alignment both in high and low frequencies (Figure \ref{fig:t_sensitivity_diagonal_1}). This behavior can be explained with the same arguments used in the previous section: low values of the kernel width correspond to a very peaked kernel, that causes all the weights to be close to zero and thus the graph becomes less and less connected loosing every capability of identifying different frequencies; on the opposite side high values of the kernel width correspond to a very flat kernel, and thus the graph loses the capacity of individuating high frequencies as discussed before.

\subsubsection{Putting it together: full graph, $n\to\infty$ and $t\to 0$}
A heuristic grid search has been used to find the following optimal kernel width for different values of $N_{side}$, always in the case of a full graph. The optimal values of the kernel width $t$ are shown in figure \ref{fig:t}, and the usual alignment plots in figures \ref{fig:optimal graph}, \ref{fig:optimal graph diagonal}. We can see in figure \ref{fig:t} that the heuristic way of \cite{DeepSphere} of setting the standard deviation $t$ produces results very close to the optimal value. We recall that in DeepSphere $t$ is set to the average of the non zeros weight matrix entries, where the number of neighbors of each node is fixed between 7 and 8. It can be seen that the optimal values of $t$ are very close to a linear trend in the log-log plot, showing some kind of polynomial relationship with the parameter $N_{side}$ that could be used to extrapolate possible values of $t$ for higher $N_{side}$.

\begin{figure}[h]
	\label{fig:t}
	
	\centering
	\includegraphics[width=0.4\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/kernelwidth.png}
\caption{Standard deviation of the Gaussian kernel  in a log-log plot. A straight line indicates a polynomial relation.}
\end{figure}

\begin{figure}[h]
	\label{fig:optimal graph}
	
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/optimal_full.png}	
\caption{Alignment of eigenspaces for the optimal sequence $(t_n)$}
\end{figure}
\begin{figure}[h]
	\label{fig:optimal graph diagonal}
	
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/optimal_full_diagonal.png}
	\caption{Alignment of eigenspaces for the optimal sequence $(t_n)$}	
\end{figure}

in figures \ref{fig:optimal graph}, \ref{fig:optimal graph diagonal} we can appreciate that for a full graph, each time we double the parameter $N_{side}$, we approximately double the degree $\ell$ at which the graph eigenvectors are correctly aligned with the spherical harmonics.
\subsubsection{Reducing the number of neighbors}
For what it concerns how to make the graph sparse, the intuition is the following: remember that we want our graph Laplacian to approximate the operator $L^t$, that for sufficiently small $t$ approximates $\triangle$.
$$\frac{1}{n}\left(\sum_i e^{-\frac{||x_i-y||^2}{4t}}(f(y)-f(x_i)) \right) \quad \approxeq \quad \int_\mathcal M e^{-\frac{||x-y||^2}{4t}}\left(f(y)-f(x)\right)d\mu(x) $$

So far we showed how to do so optimally with a full graph; however, a full graph comes at the cost of leading to a matrix $\mathbf L_n^t$ that is full and thus to a graph filtering of the order of $\mathcal O(n^2)$. We want now to make the graph sparse such that the number of non-null entries of the Laplacian is linear $\mathcal O (n)$, making the graph filtering linear in the number of pixels. For this reason Defferrard et al. construct a nearest neighbor graph constraining the number of neighbors for each vertex to be less than 8. However, as we saw at the beginning of this section this leads to a poor alignment of the graph eigenvectors with the spherical harmonics and thus to a not so optimal rotation equivariance. Here we propose a different approach, based on the following intuition: making the graph sparse means deciding which weights $W_{i,j}=\exp{-\frac{||x_i-x_j||^2}{4t}}$ set to $0$. For this approximation to be accurate we want to set to 0 only those weights that are small enough: let's define a new graph $W'$ by fixing a threshold $k$ on $w_{i,j}=e^{-\frac{||x_i-x_j||^2}{4t}}$ such that

$$W'_{i,j} = \begin{cases}
e^{-\frac{||x_i-x_j||^2}{4t}}\quad& \text{if } e^{-\frac{||x_i-x_j||^2}{4t}} \geq k\\
0 \quad & \text{if } e^{-\frac{||x_i-x_j||^2}{4t}} < k
\end{cases}$$

By setting $k = 0.01$ here are the usual alignment plots for the graph $W'$:

\begin{center}
	\begin{tabular}{ c|c} 
		
		$N_{side}$ & Number of neighbors \\ 
		
		1 & 11 \\ 
		2 & 16 \\ 
		4 & 37 \\ 
		8 & 43 \\ 
		16 & 52 \\ 
		
	\end{tabular}
\end{center}

\begin{figure}[h]
	\label{fig:optimal_thresholded}
	\caption{Optimal construction \textbf{thresholded at $k=0.01$}}
	\centering
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/optimal_thresholded.png}	
	\includegraphics[width=0.9\textwidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/optimal_thresholded_diagonal.png}	
\end{figure}

We see that we need to increase the number of neighbors as $N_{side}$ gets bigger. Again, the intuition is the following: to have spectral convergence (a strong type of convergence) we need more and more global information and more precise.  Still, the number of neighbors grows slowly with the number of pixels, making graph convolutions still computationally efficient.

[Conclusions]
To conclude this subsection, we show in figure \ref{fig:Old spectrum}, \ref{fig:New spectrum} we show a confront between the alignment of the graph Laplacian eigenvectors and the spectra of the DeepSphere graph $W$, the starting point of this work, and  of the proposed graph $W'$. It can appreciated how the alignment plots show a much better behavior of the graph Laplacian eigenvectors, and how the eigenvalues show now the correct multiplicity. This was obtained through a careful selection of the kernel width $t$ and of the number of neighbors in accord with the theory developed in the previous section. \\
\begin{minipage}{.5\textwidth}
	\centering
	\includegraphics[width=0.9\linewidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/deepsphere_original.png}
	\includegraphics[width=0.9\linewidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/deepsphere_original_diagonal.png}
	\includegraphics[width=0.9\linewidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/05_figs/old_results3.png}
	\captionof{figure}{Alignment of the graph Laplacian eigenvectors of the DeepSphere graph $W$, the starting point of this work, and its spectrum.}
	\label{fig:Old spectrum}
\end{minipage}%
\begin{minipage}{.5\textwidth}
	\centering
	\includegraphics[width=0.9\linewidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/optimal_thresholded.png}
	\includegraphics[width=0.9\linewidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/optimal_thresholded_diagonal.png}
	\includegraphics[width=0.9\linewidth]{../codes/02.HeatKernelGraphLaplacian/HEALPix/06_figures/optimal_thresholded_eigenvalues.png}
	\captionof{figure}{Alignment of the graph Laplacian eigenvectors of the proposed graph $W'$ and its spectrum.}
	\label{fig:New spectrum}
\end{minipage}


\clearpage
\subsection{Experimental validation}
\label{sec:Experimental validation}
Here we report Frederick's results with the two different constructions
